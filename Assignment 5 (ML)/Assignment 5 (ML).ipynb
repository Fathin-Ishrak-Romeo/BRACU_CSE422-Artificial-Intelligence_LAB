{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMuV4LQvboXNBptIFaNoaMB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Preprocessed data in Assignment 4\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","\n","file_path = '/content/drive/My Drive/CSE422 LAB/Assignment 4 (ML)/Dataset/Housing Price.xlsx'\n","df = pd.read_excel(file_path)\n","\n","# Task 1: Remove null values\n","df_cleaned = df.dropna()\n","\n","# Task 2: Remove duplicate rows\n","df_cleaned = df_cleaned.drop_duplicates()\n","\n","# Task 3: Handle categorical variables (Binary encoding and One-Hot Encoding)\n","binary_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n","df_cleaned[binary_columns] = df_cleaned[binary_columns].replace({'yes': 1, 'no': 0})\n","\n","# One-Hot Encoding for 'furnishingstatus'\n","df_cleaned = pd.get_dummies(df_cleaned, columns=['furnishingstatus'], drop_first=True)\n","\n","# Task 4: Feature scaling for continuous variables\n","scaler = StandardScaler()\n","df_cleaned[['price', 'area', 'parking']] = scaler.fit_transform(df_cleaned[['price', 'area', 'parking']])\n","\n","# Task 5: Remove variables with high correlation (threshold > 0.8)\n","corr_matrix = df_cleaned.corr().abs()\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n","df_cleaned.drop(columns=to_drop, inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHQ3sgKzaD_j","executionInfo":{"status":"ok","timestamp":1727188149082,"user_tz":-360,"elapsed":3034,"user":{"displayName":"FATHIN ISHRAK","userId":"14434751500627223371"}},"outputId":"bce8582a-3e4e-444b-bd9e-6becd8057950"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","# Step 3: Separate target variable (price) and features for linear regression\n","X = df_cleaned.drop(columns=['price'])\n","y = df_cleaned['price']\n","\n","# Step 4: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Step 5: Apply Linear Regression\n","linear_model = LinearRegression()\n","linear_model.fit(X_train, y_train)\n","y_pred_linear = linear_model.predict(X_test)\n","\n","# Step 6: Evaluate Linear Regression (MSE, RMSE)\n","mse = mean_squared_error(y_test, y_pred_linear)\n","rmse = np.sqrt(mse)\n","print(f\"Linear Regression MSE: {mse}\")\n","print(f\"Linear Regression RMSE: {rmse}\")\n","\n","# Step 7: Convert 'price' into binary categories for Logistic Regression\n","threshold = y.median()\n","y_binary = (y > threshold).astype(int)\n","\n","# Step 8: Split the data into training and testing sets for logistic regression\n","X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n","\n","# Step 9: Apply Logistic Regression\n","logistic_model = LogisticRegression()\n","logistic_model.fit(X_train_log, y_train_log)\n","y_pred_log = logistic_model.predict(X_test_log)\n","\n","# Step 10: Evaluate Logistic Regression (Accuracy)\n","accuracy = accuracy_score(y_test_log, y_pred_log)\n","print(f\"Logistic Regression Accuracy: {accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ag1jAELyaGSJ","executionInfo":{"status":"ok","timestamp":1727188124266,"user_tz":-360,"elapsed":423,"user":{"displayName":"FATHIN ISHRAK","userId":"14434751500627223371"}},"outputId":"d5243abc-927c-4de0-8ecf-d18eb4b12009"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression MSE: 0.5558727137233054\n","Linear Regression RMSE: 0.7455687183105963\n","Logistic Regression Accuracy: 0.8509316770186336\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OqXAdXsPNqW","executionInfo":{"status":"ok","timestamp":1727168138004,"user_tz":-360,"elapsed":30152,"user":{"displayName":"FATHIN ISHRAK","userId":"14434751500627223371"}},"outputId":"e6475c46-2a9b-41da-831a-b818b890d03b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Linear Regression MSE: 0.5558727137233054\n","Linear Regression RMSE: 0.7455687183105963\n","Logistic Regression Accuracy: 0.8509316770186336\n"]}],"source":["# Step 1: Load and preprocess data as done in Assignment 4\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","drive.mount('/content/drive')\n","\n","# Load dataset from Google Drive\n","file_path = '/content/drive/My Drive/CSE422 LAB/Assignment 4 (ML)/Dataset/Housing Price.xlsx'\n","df = pd.read_excel(file_path)\n","\n","# Step 2: Preprocess the data (same as in Assignment 4)\n","df_cleaned = df.dropna()\n","df_cleaned = df_cleaned.drop_duplicates()\n","\n","binary_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n","df_cleaned[binary_columns] = df_cleaned[binary_columns].replace({'yes': 1, 'no': 0})\n","\n","df_cleaned = pd.get_dummies(df_cleaned, columns=['furnishingstatus'], drop_first=True)\n","\n","scaler = StandardScaler()\n","df_cleaned[['price', 'area', 'parking']] = scaler.fit_transform(df_cleaned[['price', 'area', 'parking']])\n","\n","# Remove highly correlated features\n","corr_matrix = df_cleaned.corr().abs()\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n","df_cleaned.drop(columns=to_drop, inplace=True)\n","\n","# Step 3: Separate target variable (price) and features for linear regression\n","X = df_cleaned.drop(columns=['price'])\n","y = df_cleaned['price']\n","\n","# Step 4: Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Step 5: Apply Linear Regression\n","linear_model = LinearRegression()\n","linear_model.fit(X_train, y_train)\n","y_pred_linear = linear_model.predict(X_test)\n","\n","# Step 6: Evaluate Linear Regression (MSE, RMSE)\n","mse = mean_squared_error(y_test, y_pred_linear)\n","rmse = np.sqrt(mse)\n","print(f\"Linear Regression MSE: {mse}\")\n","print(f\"Linear Regression RMSE: {rmse}\")\n","\n","# Step 7: Convert 'price' into binary categories for Logistic Regression\n","threshold = y.median()  # You can choose any threshold\n","y_binary = (y > threshold).astype(int)\n","\n","# Step 8: Split the data into training and testing sets for logistic regression\n","X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n","\n","# Step 9: Apply Logistic Regression\n","logistic_model = LogisticRegression()\n","logistic_model.fit(X_train_log, y_train_log)\n","y_pred_log = logistic_model.predict(X_test_log)\n","\n","# Step 10: Evaluate Logistic Regression (Accuracy)\n","accuracy = accuracy_score(y_test_log, y_pred_log)\n","print(f\"Logistic Regression Accuracy: {accuracy}\")\n"]}]}